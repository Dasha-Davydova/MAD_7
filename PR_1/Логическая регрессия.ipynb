{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNtcTyp1iGx2RzNYXnnwZKT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVcujhvYUXR_","executionInfo":{"status":"ok","timestamp":1695984248375,"user_tz":-180,"elapsed":249090,"user":{"displayName":"Дарья Давыдова","userId":"05827531382010452575"}},"outputId":"a2b21c09-0011-43d2-a2fe-b942f45026b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["            0         1         2         3         4         5         6    \\\n","0     -2.544364  1.540688 -1.244228  1.400808  1.525972  0.734957  0.969743   \n","1     -2.540452 -0.927798 -0.292258  0.501314 -0.080139 -0.247570 -0.246859   \n","2     -2.539231  1.540688 -0.568637  0.501314  0.151070  0.263085  1.190944   \n","3     -2.532622 -0.575157 -0.691471  0.501314  0.962950 -0.198013  0.306142   \n","4     -2.529221  1.540688 -1.182811  0.501314  0.348745 -0.124754 -0.357459   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","97225  1.093978 -0.575157 -0.138714  0.501314  0.834109  0.107949  0.637942   \n","97226  1.096181 -0.927798 -0.261549  0.501314  0.987660  0.577666  0.637942   \n","97227  1.098746 -0.575157  1.427430  0.501314  0.292267 -1.309820 -1.131661   \n","97228  1.098952 -0.575157  1.488848 -0.398181 -0.173682 -0.822866 -0.578660   \n","97229  1.102648  1.540688 -0.046588 -0.398181 -0.318409 -0.751762 -0.468060   \n","\n","            7         8         9    ...       92        93        94   \\\n","0     -0.537757 -0.578083 -0.509023  ... -0.987486  1.066448 -0.041743   \n","1     -0.537757  1.017574  1.492930  ... -0.987486 -0.338591  0.578946   \n","2     -0.537757 -0.578083  1.492930  ...  0.391203 -0.823968 -0.824352   \n","3     -0.537757 -0.578083 -1.309804  ... -0.987486 -0.594053  0.241615   \n","4      0.968527 -0.578083 -0.108632  ... -0.987486  1.347455  1.024223   \n","...         ...       ...       ...  ...       ...       ...       ...   \n","97225 -0.537757  1.017574 -0.108632  ... -0.987486 -0.568506  0.997237   \n","97226 -0.537757  1.017574 -1.309804  ... -0.987486  0.044601 -1.431548   \n","97227 -0.537757 -0.578083 -1.309804  ...  1.769891 -0.645145  1.928271   \n","97228 -0.537757  2.613231 -0.909413  ... -0.987486 -0.364137  1.995737   \n","97229 -0.537757 -0.578083 -0.509023  ... -0.987486 -0.747329  0.336068   \n","\n","            95        96        97        98        99        100       101  \n","0     -0.262922  0.640648  0.018054  0.562864 -0.551154  1.846004 -1.121494  \n","1     -0.262922  0.379585  1.066668  0.562864  0.678170  0.437788  0.043947  \n","2      0.158654  0.640648  0.018054  0.562864  0.678170  0.437788  0.490286  \n","3     -0.022021  0.269135 -1.554868  0.562864 -0.551154 -0.970428  0.837439  \n","4     -0.022021  0.680811  1.590976 -0.302485  0.678170 -0.970428 -0.228816  \n","...         ...       ...       ...       ...       ...       ...       ...  \n","97225  0.218879  0.228972  0.018054  0.562864  0.678170 -0.970428 -0.427189  \n","97226 -0.142472 -1.578386  0.542361 -0.302485 -0.551154 -0.970428 -0.253612  \n","97227  0.580230 -1.578386 -1.030561 -2.033183  0.678170  0.437788 -0.204019  \n","97228 -0.323147  0.259094  1.066668 -0.302485  0.678170  0.437788 -0.873528  \n","97229  1.242707 -1.578386  1.066668 -0.302485 -0.551154 -0.970428 -0.799138  \n","\n","[97230 rows x 102 columns]\n","Лучший результат: 71.65 %\n","Лучшие параметры: {'C': 0.01}\n","             0         1         2         3         4         5         6   \\\n","0     -2.544364  1.400808  1.525972  0.734957  0.969743 -0.537757 -0.578083   \n","1     -2.540452  0.501314 -0.080139 -0.247570 -0.246859 -0.537757  1.017574   \n","2     -2.539231  0.501314  0.151070  0.263085  1.190944 -0.537757 -0.578083   \n","3     -2.532622  0.501314  0.962950 -0.198013  0.306142 -0.537757 -0.578083   \n","4     -2.529221  0.501314  0.348745 -0.124754 -0.357459  0.968527 -0.578083   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","97225  1.093978  0.501314  0.834109  0.107949  0.637942 -0.537757  1.017574   \n","97226  1.096181  0.501314  0.987660  0.577666  0.637942 -0.537757  1.017574   \n","97227  1.098746  0.501314  0.292267 -1.309820 -1.131661 -0.537757 -0.578083   \n","97228  1.098952 -0.398181 -0.173682 -0.822866 -0.578660 -0.537757  2.613231   \n","97229  1.102648 -0.398181 -0.318409 -0.751762 -0.468060 -0.537757 -0.578083   \n","\n","             7         8         9   ...        81        82        83  \\\n","0     -0.509023 -0.332256 -0.625222  ... -0.987486  1.066448 -0.041743   \n","1      1.492930  0.578881  0.732454  ... -0.987486 -0.338591  0.578946   \n","2      1.492930 -0.332256  0.224676  ...  0.391203 -0.823968 -0.824352   \n","3     -1.309804 -1.243393 -1.170813  ... -0.987486 -0.594053  0.241615   \n","4     -0.108632 -1.243393 -1.008757  ... -0.987486  1.347455  1.024223   \n","...         ...       ...       ...  ...       ...       ...       ...   \n","97225 -0.108632 -1.243393 -1.032165  ... -0.987486 -0.568506  0.997237   \n","97226 -1.309804 -0.332256 -0.765671  ... -0.987486  0.044601 -1.431548   \n","97227 -1.309804  0.578881  0.465961  ...  1.769891 -0.645145  1.928271   \n","97228 -0.909413  1.490017  1.377080  ... -0.987486 -0.364137  1.995737   \n","97229 -0.509023  1.490017  1.634571  ... -0.987486 -0.747329  0.336068   \n","\n","             84        85        86        87        88        89        90  \n","0     -0.262922  0.640648  0.018054  0.562864 -0.551154  1.846004 -1.121494  \n","1     -0.262922  0.379585  1.066668  0.562864  0.678170  0.437788  0.043947  \n","2      0.158654  0.640648  0.018054  0.562864  0.678170  0.437788  0.490286  \n","3     -0.022021  0.269135 -1.554868  0.562864 -0.551154 -0.970428  0.837439  \n","4     -0.022021  0.680811  1.590976 -0.302485  0.678170 -0.970428 -0.228816  \n","...         ...       ...       ...       ...       ...       ...       ...  \n","97225  0.218879  0.228972  0.018054  0.562864  0.678170 -0.970428 -0.427189  \n","97226 -0.142472 -1.578386  0.542361 -0.302485 -0.551154 -0.970428 -0.253612  \n","97227  0.580230 -1.578386 -1.030561 -2.033183  0.678170  0.437788 -0.204019  \n","97228 -0.323147  0.259094  1.066668 -0.302485  0.678170  0.437788 -0.873528  \n","97229  1.242707 -1.578386  1.066668 -0.302485 -0.551154 -0.970428 -0.799138  \n","\n","[97230 rows x 91 columns]\n","Лучший результат: 71.66 %\n","Лучшие параметры: {'C': 0.01}\n","Всего героев в игре: 108\n","(97230, 199)\n","Лучший результат: 74.99 %\n","Лучшие параметры: {'C': 0.05}\n","             0         1         2         3         4         5         6   \\\n","0     -2.514875  0.474746 -0.237743 -0.137094 -0.370005 -0.532732  1.003884   \n","1     -2.513895 -1.365630 -1.207913 -1.255660 -1.145090 -0.532732 -0.593200   \n","2     -2.512377 -1.365630 -0.862057 -0.742715 -1.145090 -0.532732 -0.593200   \n","3     -2.508381 -0.445442 -0.938323 -0.537967 -1.145090  0.968865  1.003884   \n","4     -2.507087  0.474746  0.038942 -1.059534 -0.812911 -0.532732 -0.593200   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","17172  1.078106  1.394934  1.448970  1.699166  1.733795 -0.532732  1.003884   \n","17173  1.079926 -0.445442 -0.867378 -1.180227 -1.145090 -0.532732 -0.593200   \n","17174  1.080056 -1.365630 -1.174215 -1.408682 -1.255816 -0.532732 -0.593200   \n","17175  1.083875  0.474746  1.076510  0.050412 -0.370005  0.968865  2.600967   \n","17176  1.085797  0.474746 -0.039098  0.328437  0.183626 -0.532732 -0.593200   \n","\n","             7         8         9   ...        81        82        83  \\\n","0      0.305165 -0.368985  0.003979  ... -0.992369  0.450016  1.908352   \n","1      0.305165  0.567766  0.023887  ...  1.788142 -0.574649  0.836945   \n","2      1.898546 -1.305736 -1.375081  ...  0.397887 -0.399706 -0.817633   \n","3      1.101855 -1.305736 -0.920823  ...  1.788142 -1.074486 -1.034626   \n","4      0.305165  1.504517  0.945070  ... -0.992369  1.049820  0.999690   \n","...         ...       ...       ...  ...       ...       ...       ...   \n","17172 -0.093180  0.567766  0.505291  ...  0.397887  0.350049  1.989724   \n","17173  1.500200 -0.368985 -0.091940  ...  0.397887  0.125122  0.362271   \n","17174 -0.093180 -0.368985 -0.875579  ... -0.992369  0.649951  0.362271   \n","17175 -0.093180 -0.368985 -0.303685  ... -0.992369 -0.549657 -1.441490   \n","17176  0.703510  1.504517  1.241876  ...  1.788142  1.099804  0.240212   \n","\n","             84        85        86        87        88        89        90  \n","0     -0.400363  1.149479  0.017743  0.554260 -0.571552 -0.983356  3.200079  \n","1      1.723080 -1.597294  0.017743 -1.177689 -0.571552  0.433564  0.600867  \n","2     -0.466721  0.281014 -1.038655 -0.311714  0.668978 -0.983356 -0.673257  \n","3     -0.599436  0.523376  0.017743  0.554260 -0.571552  0.433564 -0.469397  \n","4     -0.400363  0.220423 -1.038655 -0.311714 -0.571552  0.433564 -0.647774  \n","...         ...       ...       ...       ...       ...       ...       ...  \n","17172 -0.466721 -1.597294  0.545942 -0.311714 -0.571552  0.433564 -0.647774  \n","17173 -0.334006  0.260817 -0.510456 -0.311714  1.909508  0.433564 -0.265537  \n","17174 -0.533078  0.816231  0.545942  0.554260  1.909508 -0.983356 -0.724222  \n","17175 -0.201290 -1.597294 -1.038655  0.554260 -1.812082 -0.983356  0.193147  \n","17176 -0.134933  0.917215  0.545942 -1.177689 -0.571552 -0.983356  0.881174  \n","\n","[17177 rows x 91 columns]\n","(17177, 199)\n","Time elapsed: 0:00:03.878672\n","[[0.48498959 0.51501041]\n"," [0.33889545 0.66110455]\n"," [0.67973181 0.32026819]\n"," ...\n"," [0.77309387 0.22690613]\n"," [0.63890744 0.36109256]\n"," [0.4696134  0.5303866 ]]\n","\n","Mинимальное значение прогноза:  0.005744518654863576\n","\n","Максимальное значение прогноза:  0.9937054597857138\n"]}],"source":["import pandas as pd\n","import datetime\n","from sklearn.model_selection import KFold\n","\n","features = pd.read_csv('features.csv', index_col='match_id')\n","features_test = pd.read_csv('./features_test.csv', index_col='match_id')\n","train_Y=features['radiant_win']\n","columns_train_difference=features.columns.difference(features_test.columns.values.tolist()).tolist()\n","features.drop(columns_train_difference, axis=1, inplace=True)\n","features.fillna(0, method=None, axis=1, inplace=True)\n","\n","# 1. Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга.\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","\n","features_sc = pd.DataFrame(data=StandardScaler().fit_transform(features))\n","print(features_sc)\n","\n","lr = LogisticRegression(n_jobs=-1)\n","grid = {'C': [0.001, 0.01, 0.05, 0.1, 1, 5]}\n","cv = KFold(n_splits=5, random_state=42, shuffle=True)\n","gs = GridSearchCV(lr, grid, scoring='roc_auc', cv=cv, verbose=0)\n","gs.fit(features_sc, train_Y)\n","print('Лучший результат:', round(gs.best_score_*100, 2), '%')\n","print('Лучшие параметры:', gs.best_params_)\n","\n","\n","# 2. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации.\n","cat_features = ['r%s_hero' % i for i in range(1, 6)]+['d%s_hero' % i for i in range(1, 6)]\n","cat_features.append('lobby_type')\n","features_new = features.drop(cat_features, axis=1)\n","features_new_sc = pd.DataFrame(data=StandardScaler().fit_transform(features_new))\n","print(features_new_sc)\n","\n","gs = GridSearchCV(lr, grid, scoring='roc_auc', cv=cv, verbose=0)\n","gs.fit(features_new_sc, train_Y)\n","print('Лучший результат:', round(gs.best_score_*100, 2), '%')\n","print('Лучшие параметры:', gs.best_params_)\n","\n","# 3. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts).\n","cat_features.remove('lobby_type')\n","N_hero = pd.Series(features[cat_features].values.flatten()).drop_duplicates().shape[0]\n","print(f'Всего героев в игре: {N_hero}')\n","\n","\n","# 4. Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев\n","import numpy as np\n","X_pick = np.zeros((features.shape[0], N_hero))\n","\n","for i, match_id in enumerate(features.index):\n","    for p in range(5):\n","        r_hero_index = int(features.loc[match_id, 'r%d_hero' % (p + 1)]) - N_hero\n","        d_hero_index = int(features.loc[match_id, 'd%d_hero' % (p + 1)]) - N_hero\n","        X_pick[i, r_hero_index] = 1\n","        X_pick[i, d_hero_index] = -1\n","\n","full_data = np.hstack([np.array(features_new_sc), X_pick])\n","print(full_data.shape)\n","\n","# 5. Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации.\n","lr = LogisticRegression(n_jobs=-1, max_iter=1000)\n","grid = {'C': np.linspace(0.03, 0.1, num=8)}\n","cv = KFold(n_splits=5, random_state=42, shuffle=True)\n","gs = GridSearchCV(lr, grid, scoring='roc_auc', cv=cv, verbose=0)\n","gs.fit(full_data, train_Y)\n","print('Лучший результат:', round(gs.best_score_*100, 2), '%')\n","print('Лучшие параметры:', gs.best_params_)\n","\n","# 6. Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной).\n","\n","features_test.fillna(0, method=None, axis=1, inplace=True)\n","\n","# Убираем категориальные признаки из тестовой выборки\n","cat_features = ['r%s_hero' % i for i in range(1, 6)]+['d%s_hero' % i for i in range(1, 6)]\n","cat_features.append('lobby_type')\n","features_test_new = features_test.drop(cat_features, axis=1)\n","\n","# Масштабируем признаки\n","features_test_new_sc = pd.DataFrame(data=StandardScaler().fit_transform(features_test_new))\n","print(features_test_new_sc)\n","\n","# \"Мешок слов\", как в 4 пункте\n","X_pick_test = np.zeros((features_test.shape[0], N_hero))\n","\n","for i, match_id in enumerate(features.index):\n","    for p in range(5):\n","        r_hero_index = int(features.loc[match_id, 'r%d_hero' % (p + 1)]) - N_hero\n","        d_hero_index = int(features.loc[match_id, 'd%d_hero' % (p + 1)]) - N_hero\n","        X_pick[i, r_hero_index] = 1\n","        X_pick[i, d_hero_index] = -1\n","\n","# Добавляем \"Мешок слов\" к отмасштабированной выборке числовых признаков тестовой выборки\n","full_features_test = np.hstack([np.array(features_test_new_sc), X_pick_test])\n","print(full_features_test.shape)\n","\n","# Обучаем модель с наилучшими параметрами по тренировочной выборке\n","start_time = datetime.datetime.now()\n","final_model = LogisticRegression(C=0.05, n_jobs=-1).fit(full_data, train_Y)\n","\n","# Предсказание вероятности на тестовой выборке\n","y_pred = final_model.predict_proba(full_features_test)\n","print('Time elapsed:', datetime.datetime.now() - start_time)\n","\n","# Проверка, что модель не получилась константной\n","print(y_pred)\n","print(\"\\nMинимальное значение прогноза: \", y_pred[:, 1].min())\n","print(\"\\nМаксимальное значение прогноза: \", y_pred[:, 1].max())\n"]}]}